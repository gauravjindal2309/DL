{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cs231n.solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the cs231n directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def conv_data2image(data):\n",
    "    return np.rollaxis(data.reshape((3,32,32)),0,3)\n",
    "\n",
    "def get_cifar10(folder):\n",
    "    tr_data = np.empty((0,32*32*3))\n",
    "    tr_labels = np.empty(1)\n",
    "    '''\n",
    "    32x32x3\n",
    "    '''\n",
    "    for i in range(1,6):\n",
    "        fname = os.path.join(folder, \"%s%d\" % (\"data_batch_\", i))\n",
    "        data_dict = unpickle(fname)\n",
    "        if i == 1:\n",
    "            tr_data = data_dict['data']\n",
    "            tr_labels = data_dict['labels']\n",
    "        else:\n",
    "            tr_data = np.vstack((tr_data, data_dict['data']))\n",
    "            tr_labels = np.hstack((tr_labels, data_dict['labels']))\n",
    "\n",
    "    data_dict = unpickle(os.path.join(folder, 'test_batch'))\n",
    "    te_data = data_dict['data']\n",
    "    te_labels = np.array(data_dict['labels'])\n",
    "\n",
    "    bm = unpickle(os.path.join(folder, 'batches.meta'))\n",
    "    label_names = bm['label_names']\n",
    "\n",
    "    return tr_data, tr_labels, te_data, te_labels, label_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    datapath = '/home/gaurav/Documents/Python/cs231n/cifar-10-batches-py'\n",
    "\n",
    "X_train, y_train, X_test, y_test, label_names10 = get_cifar10(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test the affine_forward function\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N = x.shape[0]\n",
    "D = np.prod(x.shape[1:])\n",
    "x2 = x.reshape(N,D)\n",
    "out = np.dot(x2,w) +b\n",
    "\n",
    "cache = (x,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.49834967,  1.70660132,  1.91485297],\n",
       "       [ 3.25553199,  3.5141327 ,  3.77273342]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, _ = affine_forward(x, w, b)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.76984946819e-10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print 'Testing affine_forward function:'\n",
    "print 'difference: ', rel_error(out, correct_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, w, b = cache\n",
    "  dx, dw, db = None, None, None\n",
    "  N = x.shape[0]\n",
    "  xdim = np.prod(x.shape[1:])\n",
    "  xr = x.reshape((N, xdim))\n",
    "\n",
    "  dx = dout.dot(w.transpose())\n",
    "  dx = dx.reshape(x.shape)\n",
    "\n",
    "  dw = xr.transpose().dot(dout)\n",
    "  db = dout.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out, _ = relu_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.04545455,  0.13636364],\n",
       "       [ 0.22727273,  0.31818182,  0.40909091,  0.5       ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.99999979802e-08\n"
     ]
    }
   ],
   "source": [
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-8\n",
    "print 'Testing relu_forward function:'\n",
    "print 'difference: ', rel_error(out, correct_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94583466,  0.70982355, -1.09128264,  0.48926066,  0.67368727,\n",
       "         1.83018878,  0.31909479,  1.27710599,  0.44860331,  1.31257602],\n",
       "       [ 0.23915348, -0.12447212, -0.83126281,  0.88471709, -0.17058076,\n",
       "         0.47182362,  1.63540545, -0.92109741,  1.49012407,  0.61475192],\n",
       "       [-0.43762496,  1.97973729,  0.48683223,  0.1838224 ,  1.13791651,\n",
       "        -0.24040698,  0.17491183,  0.74391765, -0.08658742, -0.04601487],\n",
       "       [-1.3796409 , -0.49122249,  0.30714041,  0.98363996, -0.27207952,\n",
       "        -0.93128278,  0.03125137,  0.73323169,  1.43641072,  0.17093756],\n",
       "       [ 0.73819355, -1.18005744,  0.8964006 ,  0.4602299 ,  0.81004812,\n",
       "         0.28860025, -0.17188221, -0.008672  ,  0.07299663, -1.34517345],\n",
       "       [-0.08724678,  1.37652847,  0.86084411,  0.07849934,  1.77173336,\n",
       "        -1.65426537, -0.66516038, -0.23146378, -0.78615232,  0.34994894],\n",
       "       [-0.57148745, -0.92186553,  0.48580768,  1.16294281,  0.98694848,\n",
       "         0.10621131, -0.66107006, -0.64541479, -1.69917816,  0.51350537],\n",
       "       [ 0.8403423 , -2.51383667, -0.43783508, -0.65995437, -2.37613055,\n",
       "         0.45227893,  0.66772789, -2.22612495,  1.67524705, -0.71627626],\n",
       "       [ 0.04769461,  0.98131799, -0.03692937,  0.12324971,  0.66190747,\n",
       "         0.52517884, -0.46308584, -0.35886285, -0.39290291, -0.07652063],\n",
       "       [ 0.6073259 , -0.69588769, -0.20677358, -1.3828455 ,  0.83863522,\n",
       "         1.66915583,  2.24462611, -0.34164579, -0.39640205,  0.62360028]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx = relu_backward(dout, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dx = dout*1*(np.maximum(x,0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward:\n",
      "dx error:  5.90415485019e-10\n",
      "dw error:  1.57679861409e-10\n",
      "db error:  1.89289417491e-11\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "print 'Testing affine_relu_forward:'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw error: ', rel_error(dw_num, dw)\n",
    "print 'db error: ', rel_error(db_num, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  N = x.shape[0]\n",
    "  correct_class_scores = x[np.arange(N), y]\n",
    "  margins = np.maximum(0, x - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "  margins[np.arange(N), y] = 0\n",
    "  loss = np.sum(margins) / N\n",
    "  num_pos = np.sum(margins > 0, axis=1)\n",
    "  dx = np.zeros_like(x)\n",
    "  dx[margins > 0] = 1\n",
    "  dx[np.arange(N), y] -= num_pos\n",
    "  dx /= N\n",
    "  return loss, dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = x.shape[0]\n",
    "correct_class_scores = x[np.arange(N), y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "margins = np.maximum(0, x - correct_class_scores[:, np.newaxis] + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "margins[np.arange(N), y] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = np.sum(margins) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  N = x.shape[0]\n",
    "  correct_class_scores = x[np.arange(N), y]\n",
    "  margins = np.maximum(0, x - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "  margins[np.arange(N), y] = 0\n",
    "  loss = np.sum(margins) / N\n",
    "  num_pos = np.sum(margins > 0, axis=1)\n",
    "  dx = np.zeros_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  N = x.shape[0]\n",
    "  correct_class_scores = x[np.arange(N), y]\n",
    "  margins = np.maximum(0, x - correct_class_scores[:, np.newaxis] + 1.0)\n",
    "  margins[np.arange(N), y] = 0\n",
    "  loss = np.sum(margins) / N\n",
    "  num_pos = np.sum(margins > 0, axis=1)\n",
    "  dx = np.zeros_like(x)\n",
    "  dx[margins > 0] = 1\n",
    "  dx[np.arange(N), y] -= num_pos\n",
    "  dx /= N\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dx[margins > 0] = 1\n",
    "dx[np.arange(N), y] -= num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dx = np.zeros_like(x)\n",
    "dx[margins > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  probs = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "  probs /= np.sum(probs, axis=1, keepdims=True)\n",
    "  N = x.shape[0]\n",
    "  loss = -np.sum(np.log(probs[np.arange(N), y])) / N\n",
    "  dx = probs.copy()\n",
    "  dx[np.arange(N), y] -= 1\n",
    "  dx /= N\n",
    "  return loss, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10007313,  0.10011748,  0.10014819,  0.1000394 ,  0.10007745,\n",
       "        0.09998321,  0.09997677,  0.09994484,  0.10002709,  0.09996158,\n",
       "        0.10005151,  0.10009376,  0.10014602,  0.09993867,  0.09986448,\n",
       "        0.09996712,  0.10003742,  0.09995007,  0.10011121,  0.099981  ,\n",
       "        0.10021223,  0.09992489,  0.10017925,  0.09998462,  0.09998643,\n",
       "        0.10006327,  0.10003683,  0.0999227 ,  0.1000533 ,  0.09990354,\n",
       "        0.10002631,  0.10009986,  0.10011683,  0.09993946,  0.09987121,\n",
       "        0.10002211,  0.09995946,  0.09997311,  0.09999233,  0.10008174,\n",
       "        0.09996966,  0.09998062,  0.10013586,  0.09999868,  0.09995211,\n",
       "        0.10010781,  0.0999953 ,  0.09989033,  0.10017289,  0.09988456])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  probs = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "  probs /= np.sum(probs, axis=1, keepdims=True)\n",
    "  N = x.shape[0]\n",
    "  probs[np.arange(N), y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-115.11999623804763"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(probs[np.arange(N), y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-2\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010279845680646785"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params['W1'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing test-time forward pass ... \n"
     ]
    }
   ],
   "source": [
    "print 'Testing test-time forward pass ... '\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.loss(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.53165108,  12.2917344 ,  13.05181771,  13.81190102,\n",
       "         14.57198434,  15.33206765,  16.09215096],\n",
       "       [ 12.05769098,  12.74614105,  13.43459113,  14.1230412 ,\n",
       "         14.81149128,  15.49994135,  16.18839143],\n",
       "       [ 12.58373087,  13.20054771,  13.81736455,  14.43418138,\n",
       "         15.05099822,  15.66781506,  16.2846319 ]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running numeric gradient check with reg =  0.0\n",
      "Running numeric gradient check with reg =  0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.393662760600318"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for reg in [0.0, 0.7]:\n",
    "  print 'Running numeric gradient check with reg = ', reg\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-d29dd5f6a5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'solver' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAD1CAYAAABnTDDGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDyqB2JftG/tGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f925b9e6990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  0.0\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  0.0\n"
     ]
    }
   ],
   "source": [
    "for reg in [0, 3.14]:\n",
    "  print 'Running check with reg = ', reg\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print 'Initial loss: ', loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
